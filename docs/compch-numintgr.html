<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Probation review report</title>
  <meta name="description" content="Probation review report">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Probation review report" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="ellessenne/prr" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Probation review report" />
  
  
  

<meta name="author" content="Alessandro Gasparini">


<meta name="date" content="2017-08-21">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="compch.html">
<link rel="next" href="compch-numdiff.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="terminology-notation.html"><a href="terminology-notation.html"><i class="fa fa-check"></i><b>1</b> Terminology and notation</a></li>
<li class="chapter" data-level="2" data-path="smre.html"><a href="smre.html"><i class="fa fa-check"></i><b>2</b> Survival models with random effects</a><ul>
<li class="chapter" data-level="2.1" data-path="smre-univariate-frailty.html"><a href="smre-univariate-frailty.html"><i class="fa fa-check"></i><b>2.1</b> Univariate frailty models</a></li>
<li class="chapter" data-level="2.2" data-path="smre-shared-frailty.html"><a href="smre-shared-frailty.html"><i class="fa fa-check"></i><b>2.2</b> Shared frailty models</a></li>
<li class="chapter" data-level="2.3" data-path="smre-random-effects.html"><a href="smre-random-effects.html"><i class="fa fa-check"></i><b>2.3</b> Alternative formulation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="jm.html"><a href="jm.html"><i class="fa fa-check"></i><b>3</b> Joint models for longitudinal and survival data</a><ul>
<li class="chapter" data-level="3.1" data-path="jm-formulation.html"><a href="jm-formulation.html"><i class="fa fa-check"></i><b>3.1</b> Model formulation</a></li>
<li class="chapter" data-level="3.2" data-path="jm-estimation.html"><a href="jm-estimation.html"><i class="fa fa-check"></i><b>3.2</b> Estimation process</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="compch.html"><a href="compch.html"><i class="fa fa-check"></i><b>4</b> Computational challenges in survival models with random effects</a><ul>
<li class="chapter" data-level="4.1" data-path="compch-numintgr.html"><a href="compch-numintgr.html"><i class="fa fa-check"></i><b>4.1</b> Numerical integration</a><ul>
<li class="chapter" data-level="4.1.1" data-path="compch-numintgr.html"><a href="compch-numintgr.html#compch-numintgr-uni"><i class="fa fa-check"></i><b>4.1.1</b> Unidimensional functions</a></li>
<li class="chapter" data-level="4.1.2" data-path="compch-numintgr.html"><a href="compch-numintgr.html#compch-numintgr-multi"><i class="fa fa-check"></i><b>4.1.2</b> Multidimensional functions</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="compch-numdiff.html"><a href="compch-numdiff.html"><i class="fa fa-check"></i><b>4.2</b> Numerical differentiation</a></li>
<li class="chapter" data-level="4.3" data-path="compch-numroot.html"><a href="compch-numroot.html"><i class="fa fa-check"></i><b>4.3</b> Numerical root finding</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simsurv.html"><a href="simsurv.html"><i class="fa fa-check"></i><b>5</b> Simulating survival data</a></li>
<li class="chapter" data-level="6" data-path="simst1.html"><a href="simst1.html"><i class="fa fa-check"></i><b>6</b> Simulation study: accuracy of Gaussian quadrature</a><ul>
<li class="chapter" data-level="6.1" data-path="simst1-aim.html"><a href="simst1-aim.html"><i class="fa fa-check"></i><b>6.1</b> Aim</a></li>
<li class="chapter" data-level="6.2" data-path="simst1-dgms.html"><a href="simst1-dgms.html"><i class="fa fa-check"></i><b>6.2</b> Data-generating mechanisms</a></li>
<li class="chapter" data-level="6.3" data-path="simst1-methods.html"><a href="simst1-methods.html"><i class="fa fa-check"></i><b>6.3</b> Methods</a></li>
<li class="chapter" data-level="6.4" data-path="simst1-est.html"><a href="simst1-est.html"><i class="fa fa-check"></i><b>6.4</b> Estimands</a></li>
<li class="chapter" data-level="6.5" data-path="simst1-pm.html"><a href="simst1-pm.html"><i class="fa fa-check"></i><b>6.5</b> Performance measures</a></li>
<li class="chapter" data-level="6.6" data-path="simst1-res.html"><a href="simst1-res.html"><i class="fa fa-check"></i><b>6.6</b> Results</a><ul>
<li class="chapter" data-level="6.6.1" data-path="simst1-res.html"><a href="simst1-res.html#aim-1-comparison-of-gaussian-quadrature-with-analytical-formulae"><i class="fa fa-check"></i><b>6.6.1</b> Aim 1: comparison of Gaussian quadrature with analytical formulae</a></li>
<li class="chapter" data-level="6.6.2" data-path="simst1-res.html"><a href="simst1-res.html#aim-2-accuracy-when-analytical-formulae-are-not-available"><i class="fa fa-check"></i><b>6.6.2</b> Aim 2: accuracy when analytical formulae are not available</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="simst1-conclusions.html"><a href="simst1-conclusions.html"><i class="fa fa-check"></i><b>6.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="simst2.html"><a href="simst2.html"><i class="fa fa-check"></i><b>7</b> Simulation study: impact of misspecification in survival models with shared frailty terms</a><ul>
<li class="chapter" data-level="7.1" data-path="simst2-aim.html"><a href="simst2-aim.html"><i class="fa fa-check"></i><b>7.1</b> Aim</a></li>
<li class="chapter" data-level="7.2" data-path="simst2-dgms.html"><a href="simst2-dgms.html"><i class="fa fa-check"></i><b>7.2</b> Data-generating mechanisms</a></li>
<li class="chapter" data-level="7.3" data-path="simst2-methods.html"><a href="simst2-methods.html"><i class="fa fa-check"></i><b>7.3</b> Methods</a></li>
<li class="chapter" data-level="7.4" data-path="simst2-est.html"><a href="simst2-est.html"><i class="fa fa-check"></i><b>7.4</b> Estimands</a></li>
<li class="chapter" data-level="7.5" data-path="simst2-pm.html"><a href="simst2-pm.html"><i class="fa fa-check"></i><b>7.5</b> Performance measures</a></li>
<li class="chapter" data-level="7.6" data-path="simst2-res.html"><a href="simst2-res.html"><i class="fa fa-check"></i><b>7.6</b> Results</a></li>
<li class="chapter" data-level="7.7" data-path="simst2-conclusions.html"><a href="simst2-conclusions.html"><i class="fa fa-check"></i><b>7.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sirex.html"><a href="sirex.html"><i class="fa fa-check"></i><b>8</b> Exploring results from simulation studies interactively</a></li>
<li class="chapter" data-level="9" data-path="infvp.html"><a href="infvp.html"><i class="fa fa-check"></i><b>9</b> Informative visiting process</a></li>
<li class="chapter" data-level="10" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>10</b> Future research developments</a></li>
<li class="chapter" data-level="11" data-path="pdevelop.html"><a href="pdevelop.html"><i class="fa fa-check"></i><b>11</b> Personal development</a><ul>
<li class="chapter" data-level="11.1" data-path="supervisory-meetings.html"><a href="supervisory-meetings.html"><i class="fa fa-check"></i><b>11.1</b> Supervisory meetings</a></li>
<li class="chapter" data-level="11.2" data-path="training-and-courses.html"><a href="training-and-courses.html"><i class="fa fa-check"></i><b>11.2</b> Training and courses</a></li>
<li class="chapter" data-level="11.3" data-path="conferences.html"><a href="conferences.html"><i class="fa fa-check"></i><b>11.3</b> Conferences</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="ax-tables.html"><a href="ax-tables.html"><i class="fa fa-check"></i><b>A</b> Tables</a></li>
<li class="chapter" data-level="B" data-path="ax-plots.html"><a href="ax-plots.html"><i class="fa fa-check"></i><b>B</b> Plots</a></li>
<li class="chapter" data-level="C" data-path="ax-slides.html"><a href="ax-slides.html"><i class="fa fa-check"></i><b>C</b> Slides</a><ul>
<li class="chapter" data-level="C.1" data-path="ax-slides-safjr.html"><a href="ax-slides-safjr.html"><i class="fa fa-check"></i><b>C.1</b> 2017 SAfJR Conference</a></li>
<li class="chapter" data-level="C.2" data-path="ax-slides-sam-iscb.html"><a href="ax-slides-sam-iscb.html"><i class="fa fa-check"></i><b>C.2</b> 2017 SAM Conference and ISCB Conference</a></li>
<li class="chapter" data-level="C.3" data-path="ax-slides-students-day.html"><a href="ax-slides-students-day.html"><i class="fa fa-check"></i><b>C.3</b> Students’ Day at the 2017 ISCB Conference</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="ax-manuscript.html"><a href="ax-manuscript.html"><i class="fa fa-check"></i><b>D</b> Manuscript draft</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probation review report</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="compch-numintgr" class="section level2">
<h2><span class="header-section-number">4.1</span> Numerical integration</h2>
<p>The term <em>numerical integration</em> implies the approximation of the integral of a function; generally, it aims to use the minimum number of function evaluations possible as it tends to be numerically expensive. There is a variety of methods being proposed in literature to perform numerical integration; throughout this Section, I will focus on <em>quadrature rules</em>, i.e. any method that evaluates the function to be integrated at some points over the integration domain and combines the resulting values to obtain an approximation of the integral. Quadrature rules vary in complexity and accuracy, and generally accuracy improves as rules get more complex. Additionally, integration of functions in few dimensions is generally not too problematic; the task becomes more difficult when integrating over many dimensions as obtaining an acceptable level of accuracy often requires an unfeasible number of function evaluations.</p>
<div id="compch-numintgr-uni" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Unidimensional functions</h3>
<p>The simplest method to approximate the integral of a unidimensional function numerically is given by the <em>Riemann sum</em>. A Riemann sum is an approximation of the integral of a continuous function <span class="math inline">\(f(x)\)</span> over an integration domain <span class="math inline">\([a,b]\)</span> by a finite sum, defined as: <span class="math display">\[
\int_a^b f(x) \ dx \approx \sum_{i = 1} ^ N f(x_i^{*})\Delta(x_i),
\]</span> with <span class="math inline">\(P = \{[x_0, x_1], [x_1, x_2], \dots, [x_{N-1}, x_N]\}\)</span> a partition of <span class="math inline">\([a,b]\)</span> such that <span class="math inline">\(a = x_0 &lt; x_1 &lt; x_2 &lt; \dots &lt; x_{N-1} &lt; x_N = b\)</span>, <span class="math inline">\(\Delta(x_i) = x_i - x_{i-1}\)</span>, and <span class="math inline">\(x_i^{*} \in [x_{i-1}, x_i]\)</span>. <span class="math inline">\(x_i^{*}\)</span> can be defined in many ways: it could be the left extremity of <span class="math inline">\(\Delta(x_i)\)</span>, the right extremity, the midpoint, or many more. In particular, when choosing <span class="math inline">\(x_i^{*}\)</span> as the midpoint of the interval, I obtain the so called <em>midpoint rule</em>; it approximates the integral of a continuous function <span class="math inline">\(f(x)\)</span> by the area under a set of <span class="math inline">\(N\)</span> step functions, with the midpoint of each matching <span class="math inline">\(f\)</span>: <span class="math display">\[
\int_a^b f(x) \ dx \approx \frac{b - a}{N} \sum_{i = 1}^N f(a + (i - 0.5)(b - a) / N)
\]</span> An alternative to the midpoint rule is given by the <em>trapezoidal rule</em>, which approximates the area under a continuous function <span class="math inline">\(f(x)\)</span> as a trapezoid and then computes its area: <span class="math display">\[
\int_a^b f(x) \ dx \approx (b - a) \left[ \frac{f(a) + f(b)}{2} \right]
\]</span> it works best when partitioning the integration area into many subinterval, applying the trapezoidal rule to all of them, and then sum the results: <span class="math display">\[
\int_a^b f(x) \ dx \approx \sum_{i = 1} ^ N \frac{f(x_{k - 1}) + f(x)}{2} \Delta(x_k),
\]</span> with <span class="math inline">\({x_k}\)</span> a partition of <span class="math inline">\([a, b]\)</span> such that <span class="math inline">\(a = x_0 &lt; x_1 &lt; x_2 &lt; \dots &lt; X_{N-1} &lt; x_N = b\)</span> and <span class="math inline">\(\Delta(x_k) = x_k - x_{k - 1}\)</span> the length of the <span class="math inline">\(k\)</span><sup>th</sup> subinterval.</p>
<p>Accuracy of the midpoint and trapezoidal rules depends on the number of steps (subintervals) <span class="math inline">\(N\)</span> used to approximate the function, but so does complexity (computationally speaking). The only requirement for applying these rules is that one needs to be able to evaluate the function <span class="math inline">\(f(x)\)</span> at a given point over its domain. If <span class="math inline">\(f(x)\)</span> is cheap to evaluate, than the midpoint and trapezoidal rules may be just fine; otherwise, it would be better to move onto more complicated methods that yield more accurate results.</p>
<p>A first method that is only slightly more complicated but yields better results is the <em>Simpson’s rule</em>. It works analogously to the midpoint and trapezoidal rule, but using a smooth quadratic interpolant which takes the same values as <span class="math inline">\(f(x)\)</span> at the extremities of the integration interval <span class="math inline">\([a, b]\)</span> and at the midpoint <span class="math inline">\(m = (a + b) / 2\)</span>: <span class="math display">\[
\int_a^b f(x) \ dx \approx \frac{b - a}{6} \left[ f(a) + 4f((a + b) / 2) + f(b) \right]
\]</span> Analogously as the trapezoidal rule, it is possible to obtain greater accuracy by splitting the integration interval into many subintervals, applying the Simpson’s rule to each subinterval, and sum the results.</p>
<p>Second, it is possible to show that by choosing carefully the points at which to evaluate <span class="math inline">\(f(x)\)</span> and the weights assigned to each point it is possible to obtain an exact approximation of the integral of any polynomial of degree <span class="math inline">\(2N - 1\)</span> or less with <span class="math inline">\(N\)</span> function evaluations (proof in <span class="citation">Monahan (<a href="#ref-monahan_2011">2011</a>)</span>). Let <span class="math inline">\(f(x)\)</span> be a function of order <span class="math inline">\(2N - 1\)</span> or less to integrate over a domain <span class="math inline">\([a,b]\)</span>; let <span class="math inline">\(w(x)\)</span> be a weight function. The quadrature formula is defined as: <span class="math display">\[
\int_a^b f(x) w(x) \ dx = \sum_{i = 1} ^ N w_i f(x_i)
\]</span> Depending on the choice of the weighting function <span class="math inline">\(w(x)\)</span>, different Gaussian quadrature rules can be obtained. When <span class="math inline">\(w(x) = 1\)</span>, the associated polynomials are Legendre polynomials, the quadrature rule is then named <em>Gauss-Legendre</em> quadrature rule, and it allows integrating over the interval <span class="math inline">\([-1,1]\)</span>. The integration points are then obtained as the the <span class="math inline">\(N\)</span> roots of the Legendre polynomials: <span class="math inline">\(x = \{x_1, x_2, \dots, x_N\}\)</span>. When choosing the weight function <span class="math inline">\(\exp(-x)\)</span> the associated polynomials are Laguerre polynomials, the quadrature rule is named <em>Gauss-Laguerre</em> quadrature rule, and the integration domain is <span class="math inline">\([0, +\infty)\)</span>. Finally, when choosing the weight function <span class="math inline">\(\exp(-x^2)\)</span> the associated polynomials are Hermite polynomials, the quadrature rule is named <em>Gauss-Hermite</em> quadrature rule, and the integration domain is <span class="math inline">\((-\infty, +\infty)\)</span>. Interestingly, the Gauss-Hermite quadrature can be re-formulated using a normal density kernel with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> as weighting function: <span class="math display">\[
\int_{-\infty}^{+\infty} f(x) \phi(x | \mu, \sigma^2) \ dx = \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} f(x) \exp\left[ -\frac{(x - \mu) ^ 2}{2 \sigma ^ 2} \right] \ dx
\]</span> By applying the change of variable <span class="math inline">\(x = \mu + \sigma \sqrt{2} r\)</span>, the integral to approximate becomes <span class="math display">\[
\int_{-\infty}^{+\infty} f(x) \phi(x | \mu, \sigma^2) \ dx = \frac{\sqrt{2} \sigma}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} f(\mu + \sigma \sqrt{2} r) \exp (-r^2) \ dr,
\]</span> which can then be approximated by the quadrature rule <span class="math display">\[
\frac{\sqrt{2} \sigma}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} f(\mu + \sigma \sqrt{2} r) \exp (-r^2) \ dr \approx \sum_{i = 1} ^ N f(\mu + \sigma \sqrt{2} r) \frac{w_i}{\sqrt{\pi}}.
\]</span> That is, a quadrature rule based on the normal kernel as weight function with nodes <span class="math inline">\(\mu + \sigma \sqrt{2} x_i\)</span> and weights <span class="math inline">\(w_i / \sqrt{\pi}\)</span> (<span class="math inline">\(x_i\)</span> and <span class="math inline">\(w_i\)</span> being the nodes and weights of the corresponding <span class="math inline">\(N\)</span>-points Gauss-Hermite quadrature rule based on the usual weighting function).</p>
<p>A slightly more complicated version of Gaussian quadrature is given by the <em>Gauss–Kronrod</em> quadrature formula. In the Gauss-Kronrod quadrature rule the evaluation points are chosen dynamically so that an accurate approximation can be computed by re-using the information produced by the computation of a less accurate approximation. In practice, integration points from previous iterations can be reused as part of the new set of points, whereas usual Gaussian quadrature would require recomputation of all abscissas at each iteration. This is particularly important when some specified degree of accuracy is needed but the number of points needed to achieve this accuracy is not known ahead of time. Despite this, the quadrature rule is the same as before, i.e. <span class="math inline">\(\int_{a}^{b} f(x) \ dx \approx \sum_{i = 1} ^ {n} w_{i} f(x_{i})\)</span>. Gauss-Kronrod quadrature rule is implemented in R as the <code>integrate()</code> function.</p>
</div>
<div id="compch-numintgr-multi" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Multidimensional functions</h3>
<p>Finally, all the methods I presented so far only only apply to the integration of unidimensional functions. It is of course possible to extend quadrature rules to multidimensional settings, by recursively applying unidimensional quadrature rules. Say I want to approximate the integral of a bidimensional function <span class="math inline">\(f(x, y)\)</span>; the bidimensional Gaussian quadrature rule has the form: <span class="math display">\[
\int_X \int_Y f(x, y) \ dx \ dy \approx \sum_j \sum_i w_j w_i f(x_j, y_i)
\]</span> This can be extended to any number of dimensions <span class="math inline">\(d\)</span>, but it gets very computationally expensive very quickly as a <span class="math inline">\(N\)</span>-points rule requires <span class="math inline">\(N^d\)</span> function evaluations.</p>
<p>A better option when the number of dimensions <span class="math inline">\(d\)</span> to integrate over is high is given by <em>Monte Carlo</em> integration. Consider integrating a multidimensional function <span class="math inline">\(f(x)\)</span> over some region <span class="math inline">\(\Omega\)</span> of volume <span class="math inline">\(V(\Omega)\)</span>: <span class="math display">\[
I_{\Omega} = \int_{\Omega} f(x) \ dx = E[f(U)] V(\Omega),
\]</span> with <span class="math inline">\(U \sim\)</span> uniform over <span class="math inline">\(\Omega\)</span>. Drawing <span class="math inline">\(N\)</span> uniform random vectors <span class="math inline">\(u_i\)</span> an estimator for <span class="math inline">\(I_{\Omega}\)</span> is <span class="math display">\[
\hat{I}_{\Omega} = \frac{V(\Omega)}{N} \sum_{i = 1} ^ N f(u_i),
\]</span> and this defines Monte Carlo integration. The variance of the estimated integral <span class="math inline">\(\hat{I}_{\Omega}\)</span> follows, assuming the <span class="math inline">\(u_i\)</span> are independenent, as <span class="math inline">\(var(\hat{I}_{\Omega}) = \frac{V(\Omega)^2}{N^2} N var(f(u_i))\)</span>. More details in <span class="citation">Monahan (<a href="#ref-monahan_2011">2011</a>)</span>.</p>
<p>Luckily, both Gaussian quadrature and Monte Carlo integration can be tweaked to improve accuracy and convergence rates: two appealing options are, respectively, adaptive Gaussian quadrature and importance sampling. Adaptive Gaussian quadrature works best when using the Gauss-Hermite rule with the normal density kernel as weighting function; in a multivariate setting, using an iterative algorithm, it is possible to update the mean vector <span class="math inline">\(M\)</span> and variance-covariance matrix <span class="math inline">\(\Sigma\)</span> of the multivariate normal density at each step (e.g. using empirical Bayes estimates of <span class="math inline">\(M, \Sigma\)</span>) to better adapt the grid of quadrature points to the actual shape of the integral to approximate. Conversely, Monte Carlo integration works best when it is possible to draw a sample from the target distribution (i.e. the distribution of the integral to approximate); unfortunately, that is rarely the case in practice. The idea of importance sampling consists then in drawing a sample from a proposal distribution and then re-weight the estimated integral using importance weights to better adapt to the target distribution.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-monahan_2011">
<p>Monahan, John F. 2011. <em>Numerical Methods of Statistics</em>. 2nd ed. Statistical and Probabilistic Mathematics. Cambridge University Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="compch.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="compch-numdiff.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["Probation_review_report_AG.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
