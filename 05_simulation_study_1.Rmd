# Simulation study: accuracy of Gaussian quadrature {#simst1}
\chaptermark{Accuracy of Gaussian quadrature}

In this Chapter I will present the first, small simulation study I run during my first year, on accuracy on Gaussian quadrature methods. The aim of this simulation study is two-fold: assessing the accuracy of Gaussian quadrature using available analytical formulae as a control method, and assessing the accuracy of Gaussian quadrature when analytical formulae are not available (and therefore quadrature is indeed required). I presented part of this work as an oral presentation at the 2017 Survival Analysis for Junior Researchers conference; more details in Chapter \@ref(pdevelop) and slides available in Appendix \@ref(ax-slides-safjr).

## Data-generating mechanisms {#simst1-dgms}

I generated survival data from a Weibull distribution with shape parameter \(\lambda\) = 0.5, scale parameter \(p\) = 0.6, and parametrised as \(h(t) = \lambda p t ^ {p - 1}\) using the method of @bender_2005, and applying administrative censoring at time \(t\) = 5. I included a binary covariate simulated by drawing from a Bernoulli random variable with parameter \(\pi\) = 0.5, and a frailty term shared between individuals in a cluster by drawing first from a Gamma distribution with shape parameter \(1 / \theta\) and scale parameter \(\theta\) (for identifiability purposes) and then by drawing from a normal distribution with mean \(\mu\) = 0 and standard deviation \(\sigma = \sqrt{\theta}\). I varied \(\theta\): \(\theta\) = {0.25, 0.75, 1.25}. I also varied the regression coefficient \(\beta\) associated with the binary covariate: \(\beta\) = {-0.50, 0.00, 0.50}. I simulated data for six different sample sizes: 15 clusters of 30, 100, or 500 individuals each; 50 clusters of 30 or 100 individuals; 1000 clusters of 2 individuals. Sample size varied between 450 and 7500 individuals. Applying a fully factorial design, it resulted in 3 times 2 times 3 times 6 = 108 different data-generating mechanisms, and for each of them I generated 1000 datasets.

The 54 simulated scenarios with a Gamma frailty will be used to answer the first aim of the simulation study, as it is possible to derive an analytical formulation of the likelihood. The remaining 54 scenarios with a log-normal frailty will be used to answer the second aim.

## Methods, estimands, and performance measures {#simst1-methods-est-pm}

I fitted a set of models for each simulated dataset under each data-generating mechanism. Specifically, for the data generated assuming a Gamma frailty, I compared the following models:

* a shared Gamma frailty model with a baseline Weibull hazard using the analytical formulation of the likelihood (method _AF_);

* a shared Gamma frailty model with a baseline Weibull hazard using the likelihood approximated numerically via Gaussian quadrature (specifically, a Gauss-Laguerre quadrature rule) with 15, 35, 75, and 105 nodes (methods _GQ15_, _GQ35_, _GQ75_, _GQ105_);

* a shared Gamma frailty model with a baseline Weibull hazard using the likelihood approximated numerically via Gauss-Kronrod quadrature (as implemented in R's `integrate()` function; method _IN_).

Then, for data generated assuming a log-normal frailty, I fitted a Weibull model with a random intercept using the likelihood approximated via Gauss-Hermite quadrature using 15, 35, 75, and 105 nodes (methods _GQ15_, _GQ35_, _GQ75_, _GQ105_).

For each model I compared the estimated parameters of the Weibull distribution \(\hat{\lambda}\) and \(\hat{p}\), the estimated log-treatment effect \(\hat{\beta}\), and the estimated variance of the frailty \(\hat{\theta}\).

In terms of performance measures, I am interested first of all in the performance of the maximum likelihood estimation procedure; that is, how precise is the maximum likelihood estimator. I will assess this by computing bias for each estimand, defined as \(b = E(\hat{\beta}) - \beta\).

Next, I am interested in coverage, i.e. the proportion of times the \(100 \times (1 - \alpha)\%\) confidence interval \(\hat{\beta} \pm Z_{1 - \alpha / 2} \times SE(\hat{\beta})\) includes the true value \(\beta\). This allow to assess whether the empirical coverage rate approaches the nominal coverage rate (\(100 \times (1 - \alpha)\%\)), to properly control the type I error rate for testing a null hypotesis of no effect.

Finally, I am interested in overall accuracy and therefore I will compute the mean squared error, defined as the sum of bias and variability: \((\bar{\hat{\beta}} - \beta) ^ 2 + (SE(\hat{\beta})) ^ 2\).

Summary measures for \(\lambda\), \(p\), and \(\theta\) are computed on the log-scale. For bias and coverage, I will further include Monte Carlo standard errors to quantify the uncertainty in estimating the performance measures (further details in @white_2010).

## Results {#simst1-res}

```{r load-sim1-results}
summary_an_vs_gq = read_csv("data/summary_an_vs_qg.csv.gz") %>%
  mutate(method = factor(method, levels = c("AF", "IN", "GQ15", "GQ35", "GQ75", "GQ105")),
         par = factor(par, levels = c("lambda", "p", "trt", "theta"), labels = c("Lambda", "P", "Beta", "Theta")))
summary_normal_gq = read_csv("data/summary_normal_qg.csv.gz") %>%
  mutate(method = factor(method, levels = c("GQ15", "GQ35", "GQ75", "GQ105")),
         par = factor(par, levels = c("lambda", "p", "trt", "sigma"), labels = c("Lambda", "P", "Beta", "Sigma")))
```

I selected a single scenario for each aim of this simulation study (out of 54) to present, for conciseness. Specifically, I will present results for the setting of a small frailty variance (0.25) with a negative regression coefficient (-0.50). The full results can be explored online interactively at [https://ag475.shinyapps.io/PRR-SiReX/](https://ag475.shinyapps.io/PRR-SiReX/).

### Aim 1: accuracy compared to analytical formulae

Bias, coverage, and mean squared error are presented in Tables \@ref(tab:sim1-an-vs-gq-scenario1-bias-t), \@ref(tab:sim1-an-vs-gq-scenario1-cov-t), \@ref(tab:sim1-an-vs-gq-scenario1-mse-t) and Figures \@ref(fig:sim1-an-vs-gq-scenario1-bias), \@ref(fig:sim1-an-vs-gq-scenario1-cov), \@ref(fig:sim1-an-vs-gq-scenario1-mse). Bias, coverage, and overall accuracy were optimal for all methods and across all sample sizes for the scale parameter of the Weibull distribution \(p\) and the regression coefficient \(\beta\); conversely, the methods performed quite differently for the shape parameter \(\lambda\) and the frailty variance \(\theta\). The shape parameter estimated using analytical formulae or Gauss-Kronrod quadrature was generally unbiased, with good coverage and accuracy; vice versa, using Gauss-Laguerre quadrature produced underestimated coefficients when using a small number of nodes and required at least 75 nodes to yield unbiased results. As the number of nodes increased, coverage and mean squared error improved considerably. Also, sample sizes with a higher number of clusters generally yielded better estimates for the shape parameter in terms of bias, coverage, and mean squared error. The frailty variance \(\theta\) was the parameter estimated with the greatest variability in the results. Analytical formulae required a high number of clusters to produce unbiased results (50 or 1000), yielding underestimated coefficients otherwise. Gauss-Kronrod performed similarly to analytical formulae, as did Gauss-Laguerre quadrature with a sufficiently high number of nodes. Coverage was generally good, above 90\% (except Gauss-Laguerre with 15 nodes, where coverage fell to 60-70\% in some settings), symptom of overestimated standard errors for the frailty variance; this inflation of the standard errors was reflected in the mean squared error, which was generally greater than the other estimated parameters for all methods under all sample sizes explored in this scenario.

### Aim 2: accuracy when analytical formulae are not available

Bias, coverage, and mean squared error are presented in Tables \@ref(tab:sim1-normal-gq-scenario1-bias-t), \@ref(tab:sim1-normal-gq-scenario1-cov-t), \@ref(tab:sim1-normal-gq-scenario1-mse-t), and Figures \@ref(fig:sim1-normal-gq-scenario1-bias), \@ref(fig:sim1-normal-gq-scenario1-cov), \@ref(fig:sim1-normal-gq-scenario1-mse). Bias is generally negligible for the parameters of the Weibull distribution \(\lambda\) and \(p\) and the regression coefficient \(\beta\): between 0.0059 and 0.0193 for \(\lambda\), between -0.0424 and -0.0332 for \(p\), between 0.0040 and 0.0867 for \(\beta\). Conversely, estimates for \(\sigma\) were negatively biased for a sample size of 15 clusters - 100 individuals, 1000 clusters - 2 individuals, 15 clusters - 30 individuals (between -0.3057 and -0.0854) and positively biased for a sample size of 15 clusters - 500 individuals (between and 0.2427 and 0.4020). Bias was negligible for a sample size of 50 clusters - 30 individuals and 50 clusters - 100 individuals (between -0.0536 and -0.0095). Coverage of all estimated coefficients was poor (< 75\%) for a sample size of 15 clusters - 500 individuals. For the regression coefficient \(\beta\) and the frailty variance \(\sigma\) coverage was good or superoptimal for the remaining sample sizes, with the exception of \(\sigma\) estimated using Gauss-Hermite quadrature with 15 nodes that resulted in slight undercoverage for sample sizes of 15 clusters - 100 individuals and 50 clusters - 100 individuals. The parameters of the Weibull distribution were generally undercovered (< 80\%) across sample sizes, except \(\lambda\) with a sample size of 1000 clusters - 2 individuals and \(p\) with a sample size of 15 clusters - 30 individuals for which coverage was in the range 90-95\%. Finally, mean squared error was low for \(\lambda\), \(p\), and \(\beta\), comparable for \(\sigma\) with a sample size of 50 clusters - 30 individuals and 50 clusters - 100 individuals, much higher for \(\sigma\) with all the remaining sample sizes (i.e. overall accuracy was lower in these settings).

## Conclusions {#simst1-conclusions}

I showed in the previous Section how Gaussian quadrature performs (1) compared to analytical formulae and (2) when it is not possible to obtain analytical formulae. Overall, Gaussian quadrature performs well with a sufficient number of quadrature nodes but the variability is great. The regression coefficient \(\beta\) is the most robust estimand across different scenarios, it is mostly unbiased (or with little bias) and with good coverage and accuracy (in terms of mean squared error). The frailty variance is the least robust estimand, with precision and accuracy greatly depending on many factors such as the number of quadrature nodes and the number of clusters. The latter makes sense theoretically: with more clusters, it should be easier to properly estimate a variance term. Accuracy and precision of the maximum likelihood estimator for the parameters of the Weibull baseline hazard also varied greatly. In conclusion, using a shared frailty model to do inference on a regression coefficient seems to be robust to the accuracy of numerical integration methods; nevertheless, if the principal research interest lays in relative risk estimates, using a parametric model may not be the best choice after all. A semi parametric Cox model - even with frailty terms if necessary - could be utilised instead. If the research objectives include absolute risk estimations, though, a parametric model is immediately more appealing. However, checking the convergence, precision, and accuracy of numerical integration by evaluating and comparing an increasing number of quadrature knots appears to be fundamental.
